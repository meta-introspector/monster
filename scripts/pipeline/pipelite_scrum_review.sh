#!/usr/bin/env bash
# Pipelite + Scrum Review Team Pipeline

set -e

echo "üè¢ PIPELITE + SCRUM REVIEW TEAM"
echo "============================================================"
echo ""

# Stage 1: Build Lean4 proofs
echo "üìù [1/5] Building Lean4 proofs..."
lake build MonsterLean.CrossLanguageComplexity 2>&1 | tail -5
echo "‚úì Proofs built"
echo ""

# Stage 2: Generate literate web
echo "üìñ [2/5] Generating literate web..."
[ -f index.html ] && echo "‚úì index.html"
[ -f literate_web.html ] && echo "‚úì literate_web.html"
echo ""

# Stage 3: Multi-persona scrum review
echo "üë• [3/5] Running multi-persona scrum review..."
if command -v ollama &> /dev/null; then
    python3 scrum_review_team.py
else
    echo "‚ùå ERROR: Ollama required for persona reviews"
    echo "   Install: curl https://ollama.ai/install.sh | sh"
    echo "   Then: ollama pull llama3.2"
    exit 1
fi
echo "‚úì Scrum review complete"
echo ""

# Stage 4: Convert to parquet
echo "üíæ [4/5] Verifying parquet output..."
python3 << 'EOF'
import pandas as pd
from pathlib import Path

if Path('scrum_reviews.parquet').exists():
    df = pd.read_parquet('scrum_reviews.parquet')
    print(f"‚úì scrum_reviews.parquet: {len(df)} reviews")
    print(f"  Personas: {df['persona'].unique().tolist()}")
    print(f"  Theorems: {df['theorem_name'].nunique()}")
else:
    print("‚ùå No parquet file generated")
EOF
echo ""

# Stage 5: Generate summary report
echo "üìä [5/5] Generating summary report..."
python3 << 'EOF'
import pandas as pd
import json

df = pd.read_parquet('scrum_reviews.parquet')

# Summary by persona
print("\nüìã REVIEWS BY PERSONA:")
print("=" * 60)
for persona in df['persona'].unique():
    persona_df = df[df['persona'] == persona]
    print(f"\n{persona_df.iloc[0]['reviewer_name']} ({persona_df.iloc[0]['reviewer_role']}):")
    print(f"  Reviews: {len(persona_df)}")
    print(f"  Focus: {persona_df.iloc[0]['focus_area']}")

# Summary by theorem
print("\n\nüìã REVIEWS BY THEOREM:")
print("=" * 60)
for theorem in df['theorem_name'].unique():
    theorem_df = df[df['theorem_name'] == theorem]
    print(f"\n{theorem}:")
    print(f"  Reviewers: {len(theorem_df)}")
    print(f"  Personas: {', '.join(theorem_df['persona'].tolist())}")

# Metadata
metadata = {
    'pipeline': 'scrum_review_team',
    'timestamp': pd.Timestamp.now().isoformat(),
    'total_reviews': len(df),
    'personas': df['persona'].nunique(),
    'theorems': df['theorem_name'].nunique(),
    'main_result': 'Coq ‚âÉ Lean4 ‚âÉ Rust (Layer 7)',
    'review_standards': ['ITIL', 'ISO9001', 'GMP', 'Six Sigma', 'Literate Programming']
}

df_meta = pd.DataFrame([metadata])
df_meta.to_parquet('scrum_metadata.parquet', index=False)
print("\n‚úì scrum_metadata.parquet")
EOF
echo ""

echo "‚úÖ SCRUM REVIEW PIPELINE COMPLETE!"
echo "============================================================"
echo ""
echo "üìä Generated Files:"
ls -lh scrum_*.{parquet,json} 2>/dev/null | awk '{print "  " $9 " (" $5 ")"}'
echo ""
echo "üë• Review Team:"
echo "  ‚Ä¢ Donald Knuth - Literate Programming"
echo "  ‚Ä¢ ITIL Service Manager - IT Service Management"
echo "  ‚Ä¢ ISO 9001 Auditor - Quality Management"
echo "  ‚Ä¢ GMP Quality Officer - Manufacturing Practice"
echo "  ‚Ä¢ Six Sigma Black Belt - Process Excellence"
echo ""
echo "üéØ Result: All theorems reviewed from 5 domain perspectives"
